{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset (replace with actual data)\n",
    "df = pd.read_csv('german_credit_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmploymentDuration  Risk   \n",
       "1_to_4              No Risk    878\n",
       "                    Risk       272\n",
       "4_to_7              No Risk    644\n",
       "                    Risk       468\n",
       "greater_7           Risk       520\n",
       "                    No Risk    218\n",
       "less_1              No Risk    693\n",
       "                    Risk        63\n",
       "unemployed          No Risk    236\n",
       "                    Risk         7\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Risk', 'EmploymentDuration']].groupby('EmploymentDuration').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "\n",
    "    df_fe = df.copy()\n",
    "\n",
    "    # 1. High Installment Percentage → risky if ≥ 4\n",
    "    df_fe['is_high_installment'] = (df_fe['InstallmentPercent'] >= 4).astype(int)\n",
    "\n",
    "    # 2. Young borrower → risky if Age < 40\n",
    "    df_fe['is_young'] = (df_fe['Age'] < 40).astype(int)\n",
    "\n",
    "    # 3. Long loan duration → risky if ≥ 30 months\n",
    "    df_fe['is_long_loan'] = (df_fe['LoanDuration'] >= 30).astype(int)\n",
    "\n",
    "    # 4. Large loan amount → risky if ≥ 5000\n",
    "    df_fe['is_large_loan'] = (df_fe['LoanAmount'] >= 5000).astype(int)\n",
    "\n",
    "    # 5. Long residence duation → risky if ≥ 4 years\n",
    "    df_fe['is_long_residence'] = (df_fe['CurrentResidenceDuration'] >= 4).astype(int)\n",
    "\n",
    "    # 6. No checking account\n",
    "    df_fe['no_checking'] = (df_fe['CheckingStatus'] == 'no_checking').astype(int)\n",
    "\n",
    "    # 7. Poor credit history\n",
    "    df_fe['bad_credit'] = df_fe['CreditHistory'].isin([\n",
    "        'outstanding_credit', 'prior_payments_delayed'\n",
    "    ]).astype(int)\n",
    "\n",
    "    # 8. High risk loan purpose\n",
    "    df_fe['risky_purpose'] = df_fe['LoanPurpose'].isin([\n",
    "        'appliances', 'business', 'education', 'other', 'ratio_tv', 'repairs'\n",
    "    ]).astype(int)\n",
    "\n",
    "    # 9. Employment instability → less than 1 year or unemployed\n",
    "    df_fe['long_employment'] = df_fe['EmploymentDuration'].isin([\n",
    "        'greater_7', '4_to_7'\n",
    "    ]).astype(int)\n",
    "\n",
    "    return df_fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = [\n",
    "    'LoanDuration',\n",
    "    'LoanAmount',\n",
    "    'InstallmentPercent',\n",
    "    'CurrentResidenceDuration',\n",
    "    'Age',\n",
    "    'ExistingCreditsCount',\n",
    "]\n",
    "categorical_cols = [\n",
    "  'CheckingStatus',\n",
    "  'CreditHistory',\n",
    " 'LoanPurpose',\n",
    " 'ExistingSavings',\n",
    " 'EmploymentDuration',\n",
    " 'Sex',\n",
    " 'OthersOnLoan',\n",
    " 'OwnsProperty',\n",
    " 'InstallmentPlans',\n",
    " 'Housing',\n",
    " 'Job',\n",
    " 'Dependents',\n",
    " 'Telephone',\n",
    " 'ForeignWorker',]\n",
    "\n",
    "binary_cols = [\n",
    "    'is_high_installment',\n",
    "    'is_young',\n",
    "    'is_long_loan',\n",
    "    'is_large_loan',\n",
    "    'is_long_residence',\n",
    "    'no_checking',\n",
    "    'bad_credit',\n",
    "    'long_employment',\n",
    "    'risky_purpose'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Identify categorical and numerical columns\n",
    "cat_cols = categorical_cols\n",
    "num_cols = numerical_cols\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "num_transformer = Pipeline([\n",
    "    #('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "cat_transformer = Pipeline([\n",
    "    #('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine preprocessors in a column transformer\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_transformer, num_cols),\n",
    "    ('cat', cat_transformer, cat_cols),\n",
    "    ('binary', 'passthrough', binary_cols)\n",
    "])\n",
    "\n",
    "# Choose model type (classification or regression)\n",
    "model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', )\n",
    "\n",
    "# Create full pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', model)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "def compute_costs(LoanAmount):\n",
    "     return({'Risk_No Risk': 5.0 + .6 * LoanAmount, 'No Risk_No Risk': 1.0 - .05 * LoanAmount,\n",
    "         'Risk_Risk': 1.0, 'No Risk_Risk': 1.0})\n",
    "def custom_score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str) -> float:\n",
    "   '''\n",
    "   A custom metric for the German credit dataset\n",
    "   '''\n",
    "   real_prop = {'Risk': .02, 'No Risk': .98}\n",
    "   train_prop = {'Risk': 1/3, 'No Risk': 2/3}\n",
    "   custom_weight = {'Risk': real_prop['Risk']/train_prop['Risk'], 'No Risk': real_prop['No Risk']/train_prop['No Risk']}\n",
    "   costs = compute_costs(solution['LoanAmount'])\n",
    "   y_true = solution['Risk']\n",
    "   y_pred = submission['Risk']\n",
    "   loss = (y_true=='Risk') * custom_weight['Risk'] *\\\n",
    "               ((y_pred=='Risk') * costs['Risk_Risk'] + (y_pred=='No Risk') * costs['Risk_No Risk']) +\\\n",
    "            (y_true=='No Risk') * custom_weight['No Risk'] *\\\n",
    "               ((y_pred=='Risk') * costs['No Risk_Risk'] + (y_pred=='No Risk') * costs['No Risk_No Risk'])\n",
    "   # return loss.mean()\n",
    "   return -np.mean(loss)\n",
    "\n",
    "\n",
    "# Custom scorer that needs access to X\n",
    "def cost_scorer(estimator, X, y_true):\n",
    "    # Make predictions\n",
    "    y_pred = estimator.predict(X)\n",
    "\n",
    "    # Reconstruct `solution` and `submission` DataFrames\n",
    "    solution = pd.DataFrame({\n",
    "        'Risk': ['Risk' if val == 1 else 'No Risk' for val in y_true],\n",
    "        'LoanAmount': X['LoanAmount'].values  # X must be the raw DataFrame\n",
    "    })\n",
    "\n",
    "    submission = pd.DataFrame({\n",
    "        'Risk': ['Risk' if val == 1 else 'No Risk' for val in y_pred]\n",
    "    })\n",
    "\n",
    "    return custom_score(solution, submission, row_id_column_name=None)\n",
    "\n",
    "# scorer = make_scorer(cost_scorer, greater_is_better=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target and features\n",
    "target = \"Risk\"\n",
    "X = df.drop(columns=[target])\n",
    "X = create_features(X)\n",
    "y = df[target]\n",
    "\n",
    "# Binary encode target variable if classification\n",
    "y = LabelEncoder().fit_transform(y) if y.nunique() == 2 else y\n",
    "\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# #this can be a way to find the right balance.\n",
    "# class_weights = {0: 0.8, 1: 0.2}\n",
    "# sample_weights = [class_weights[label] for label in y_train]\n",
    "\n",
    "\n",
    "# Define parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'model__n_estimators': [400, 500, 600, 700, 800],\n",
    "    'model__max_depth': [2, 3, 5, 7],\n",
    "    'model__learning_rate': [0.005, 0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "\n",
    "# Perform grid search - custom scoring loss function here?\n",
    "search = GridSearchCV(pipeline, param_grid, cv=5, scoring=cost_scorer, n_jobs=-1)\n",
    "search.fit(X_train, y_train,\n",
    "        #    model__sample_weight=sample_weights\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7825\n",
      "Best parameters: {'model__learning_rate': 0.005, 'model__max_depth': 7, 'model__n_estimators': 400}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "y_pred = search.best_estimator_.predict(X_test)\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {score:.4f}\")\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best parameters:\", search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the test dataset\n",
    "try:\n",
    "    test_df = pd.read_csv('german_credit_test.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'german_credit_test.csv' not found. Please make sure the file exists and the name is correct.\")\n",
    "    exit() # Exit the script if the file is not found\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading the test data: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Assuming you have already defined the following from the previous code block:\n",
    "# numerical_cols, categorical_cols, target, preprocessor, model, pipeline, search (with the fitted model)\n",
    "\n",
    "# Prepare the test data\n",
    "X_test_final = test_df.drop(columns=[target], errors='ignore') # Drop target column if it exists\n",
    "X_test_final = create_features(X_test_final)  # Create features\n",
    "\n",
    "# Generate predictions\n",
    "search.fit(X, y)  # Refit using the full dataset\n",
    "y_pred_final = search.best_estimator_.predict(X_test_final)\n",
    "\n",
    "\n",
    "# Optionally save predictions to a file\n",
    "predictions_df = pd.DataFrame({\n",
    "    'Id': test_df.index,\n",
    "    'Risk': y_pred_final}\n",
    "                              )\n",
    "# predictions_df.to_csv('german_credit_test_predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: Id,TARGET\n",
    "# 1, \"Risk\"\n",
    "# 2, \"No Risk\"\n",
    "# 3, \"Risk\"\n",
    "# etc.\n",
    "# is the format of the predictions df that i need.\n",
    "\n",
    "import pandas as pd\n",
    "# ... (Your existing code)\n",
    "\n",
    "# Inverse transform the predictions if necessary\n",
    "le = LabelEncoder()\n",
    "le.fit(df['Risk'])\n",
    "y_pred_final_labels = le.inverse_transform(y_pred_final)\n",
    "\n",
    "\n",
    "# Optionally save predictions to a file\n",
    "predictions_df = pd.DataFrame({\n",
    "    'Id': test_df.index,\n",
    "    'Risk': y_pred_final_labels # Use 'TARGET' as column name\n",
    "})\n",
    "#print(predictions_df['TARGET'].value_counts())\n",
    "predictions_df.to_csv('german_credit_test_predictions.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
